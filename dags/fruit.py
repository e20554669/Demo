import pandas as pd
import requests
from datetime import datetime, timedelta
import pymysql
from tqdm import tqdm

# âœ… Airflow å¥—ä»¶ï¼ˆæ–°ç‰ˆ TaskFlow APIï¼‰
from airflow import DAG
from airflow.decorators import task

# ==========================================================
# âœ… MySQL é€£ç·šè¨­å®š
# ==========================================================
DB_CONFIG = {
    "host": "35.221.176.159",   # Docker å…§é€£æœ¬æ©Ÿ MySQL
    "port": 3306,
    "user": "fruit-weatrher",
    "password": "1qaz@WSX",
    "database": "fruit_weather",
    "charset": "utf8mb4"
}

TABLE_NAME = "volume"

# ==========================================================
# âœ… API å°æ‡‰è¡¨
# ==========================================================
url = "https://data.moa.gov.tw/Service/OpenData/FromM/FarmTransData.aspx"

column_name = {
    "äº¤æ˜“æ—¥æœŸ": "TransDate",
    "å¸‚å ´ä»£è™Ÿ": "MarketCode",
    "å¸‚å ´åç¨±": "MarketName",
    "ä½œç‰©ä»£è™Ÿ": "CropCode",
    "ä¸Šåƒ¹": "UpperPrice",
    "ä¸­åƒ¹": "MiddlePrice",
    "ä¸‹åƒ¹": "LowerPrice",
    "å¹³å‡åƒ¹": "AveragePrice",
    "äº¤æ˜“é‡": "TransVolume",
    "ç¨®é¡ä»£ç¢¼": "TypeCode"
}

fruit_name = {
    "72": "ç•ªèŒ„", "I1": "æœ¨ç“œ", "51": "ç™¾é¦™æœ", "T1": "è¥¿ç“œ", "N3": "æ",
    "R1": "èŠ’æœ", "L1": "æ‡æ·", "H1": "æ–‡æ—¦æŸš", "H2": "ç™½æŸš", "Z4": "æŸ¿",
    "W1": "æ´‹é¦™ç“œ", "A1": "é¦™è•‰", "Y1": "æ¡ƒ", "45": "è‰è“", "J1": "è”æ",
    "D1": "æ¥Šæ¡ƒ", "41": "æ¢…", "O10": "æ¢¨", "V1": "é¦™ç“œ", "E1": "æŸ³æ©™",
    "22": "è“®éœ§", "C1": "æ¤ªæŸ‘", "P1": "ç•ªçŸ³æ¦´", "11": "å¯å¯æ¤°å­",
    "C5": "æº«å·èœœæŸ‘", "S1": "è‘¡è„", "H4": "è‘¡è„æŸš", "B2": "é³³æ¢¨",
    "G7": "é¾çœ¼", "K3": "æ£—", "F1": "è˜‹æœ", "X69": "é‡‹è¿¦",
}

MARKET_TO_CITY_ID = {
    "å°åŒ—ä¸€": "TPE", "å°åŒ—äºŒ": "TPE",
    "æ¿æ©‹å€": "NTP", "ä¸‰é‡å€": "NTP",
    "æ¡ƒè¾²": "TYN", "å®œè˜­å¸‚": "ILA",
    "å°ä¸­å¸‚": "TXG", "è±åŸå€": "TXG", "æ±å‹¢é®": "TXG",
    "å˜‰ç¾©å¸‚": "CYI", "é«˜é›„å¸‚": "KHH", "é³³å±±å€": "KHH",
    "å°æ±å¸‚": "TTT", "å—æŠ•å¸‚": "NTO", "å±æ±å¸‚": "PIF"
}

# ==========================================================
# ğŸ”§ å·¥å…·å‡½å¼
# ==========================================================
def roc_to_ad(date_str):
    """æ°‘åœ‹è½‰è¥¿å…ƒ"""
    if pd.isna(date_str):
        return None
    date_str = str(date_str).replace(".", "").replace("/", "")
    if len(date_str) != 7:
        return None
    y = int(date_str[:3]) + 1911
    m = int(date_str[3:5])
    d = int(date_str[5:7])
    return f"{y:04d}-{m:02d}-{d:02d}"


def fetch_data(start, end, page_top=2000):
    """æŠ“å– MOA API è³‡æ–™"""
    all_data = []
    valid_codes = set(fruit_name.keys())

    params = {
        "StartDate": f"{start.year - 1911:03d}.{start.month:02d}.{start.day:02d}",
        "EndDate": f"{end.year - 1911:03d}.{end.month:02d}.{end.day:02d}",
        "TcType": "N05",
        "$top": page_top,
        "$skip": 0
    }

    while True:
        r = requests.get(url, params=params, timeout=30)
        r.raise_for_status()
        data = r.json()
        if not data:
            break

        filtered = [i for i in data if i.get("ä½œç‰©ä»£è™Ÿ") in valid_codes]
        all_data.extend(filtered)

        if len(data) < page_top:
            break
        params["$skip"] += page_top

    return all_data


def get_last_date():
    """æŸ¥è³‡æ–™åº«ä¸­æœ€å¾Œçš„æ—¥æœŸ"""
    conn = pymysql.connect(**DB_CONFIG)
    cursor = conn.cursor()
    cursor.execute(f"SELECT MAX(date) FROM {TABLE_NAME}")
    result = cursor.fetchone()[0]
    cursor.close()
    conn.close()
    return result


def insert_to_mysql(df, batch_size=500):
    """é€ç­†åŒ¯å…¥ MySQLï¼ˆå«é€²åº¦æ¢ï¼‰"""
    conn = pymysql.connect(**DB_CONFIG)
    cursor = conn.cursor()

    sql = f"""
    INSERT INTO {TABLE_NAME}
    (date, city_id, crop_id, avg_price, trans_volume)
    VALUES (%s, %s, %s, %s, %s)
    """

    data_to_insert = [
        (
            row["date"],
            row["city_id"],
            row["crop_id"],
            float(row["avg_price"]),
            float(row["trans_volume"])
        )
        for _, row in df.iterrows()
    ]

    total = len(data_to_insert)
    print(f"ğŸ“Š é–‹å§‹åŒ¯å…¥ MySQLï¼Œå…± {total} ç­†è³‡æ–™")

    for i in tqdm(range(0, total, batch_size), desc="åŒ¯å…¥é€²åº¦", ncols=100):
        batch = data_to_insert[i:i + batch_size]
        cursor.executemany(sql, batch)
        conn.commit()

    cursor.close()
    conn.close()
    print("âœ… åŒ¯å…¥å®Œæˆï¼")

# ==========================================================
# ğŸš€ Airflow DAG with TaskFlow API
# ==========================================================
with DAG(
    dag_id="fruit_price_daily_taskflow",
    description="æ¯æ—¥æŠ“å–å°ç£æ°´æœè¡Œæƒ…ï¼ˆTaskFlow API, UTCï¼‰",
    start_date=datetime(2025, 1, 1),
    schedule="55 7 * * *",   # æ¯å¤© 11:36 UTC åŸ·è¡Œ
    catchup=False,
    tags=["fruit", "moa", "mysql"]
) as dag:

    # --- å®šç¾©ä»»å‹™ ---
    @task()
    def prepare_date_range():
        """åµæ¸¬ MySQL æœ€å¾Œæ—¥æœŸ â†’ æ±ºå®šæŠ“å–ç¯„åœ"""
        last_date = get_last_date()
        if last_date:
            start_date = last_date + timedelta(days=1)
            print(f"ğŸ“† å¾ {start_date} é–‹å§‹æŠ“å–æ–°è³‡æ–™")
        else:
            start_date = datetime(2025, 11, 1).date()
            print("ğŸ”° ç¬¬ä¸€æ¬¡åŸ·è¡Œï¼Œå¾ 2020-01-01 é–‹å§‹")

        end_date = datetime.today().date()
        if start_date > end_date:
            print("âœ… å·²æ˜¯æœ€æ–°è³‡æ–™ï¼Œç„¡éœ€æ›´æ–°")
            return None
        return (start_date, end_date)

    @task()
    def fetch_and_transform(date_range):
        """æŠ“å–èˆ‡æ¸…æ´—è³‡æ–™"""
        if not date_range:
            return None

        start_date, end_date = date_range
        records = []
        cursor_date = start_date
        while cursor_date <= end_date:
            print(f"ğŸ“… æŠ“å–æ—¥æœŸï¼š{cursor_date}")
            day_data = fetch_data(cursor_date, cursor_date)
            if day_data:
                records.extend(day_data)
            cursor_date += timedelta(days=1)

        if not records:
            print("âš ï¸ æ²’æœ‰æŠ“åˆ°ä»»ä½•è³‡æ–™")
            return None

        df = pd.DataFrame(records)
        df = df.rename(columns={col: column_name.get(col, col) for col in df.columns})
        df["TransDate"] = df["TransDate"].apply(roc_to_ad)
        df["TransDate"] = pd.to_datetime(df["TransDate"], errors="coerce")
        df["city_id"] = df["MarketName"].map(MARKET_TO_CITY_ID)

        grouped = df.groupby(
            ["TransDate", "CropCode", "city_id"],
            as_index=False
        ).agg({
            "AveragePrice": "mean",
            "TransVolume": "sum"
        })

        grouped["AveragePrice"] = grouped["AveragePrice"].round(2)
        grouped = grouped.rename(columns={
            "TransDate": "date",
            "CropCode": "crop_id",
            "AveragePrice": "avg_price",
            "TransVolume": "trans_volume"
        })

        print(f"ğŸ“¦ æ•´ç†å®Œæˆ {len(grouped)} ç­†è³‡æ–™")
        return grouped.to_dict(orient="records")

    @task()
    def insert_data(records):
        """åŒ¯å…¥ MySQL"""
        if not records:
            print("âœ… ç„¡æ–°è³‡æ–™å¯åŒ¯å…¥")
            return
        df = pd.DataFrame(records)
        insert_to_mysql(df)

    # --- DAG åŸ·è¡Œæµç¨‹ ---
    date_range = prepare_date_range()
    data = fetch_and_transform(date_range)
    insert_data(data)
